import numpy as np
import pandas as pd
import tensorflow as tf
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler 
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.utils import to_categorical # Usando tensorflow.keras
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

from gerador_DataSet import dados_solo
from SalvarModelo import salvarModelo


# Definir uma semente para reprodutibilidade dos resultados
np.random.seed(42)

# Número de amostras por classe
n_amostras_por_classe = 100

# PRE- PROCESSAMENTO DE DADOS

# 1. Separar features (X) e labels (y)
X = dados_solo.drop('Classe_Fertilidade', axis=1)
y = dados_solo['Classe_Fertilidade']
# 2. Normalizar as features
scaler = MinMaxScaler()
X_normalizado = scaler.fit_transform(X)
X_normalizado_df = pd.DataFrame(X_normalizado, columns=X.columns) # Opcional para visualização
print("\n--- Features Normalizadas (X_normalizado_df) Primeiras 5 linhas---")
print(X_normalizado_df.head())

# 3. Codificar os labels para o formato One-Hot Encoding
y_categorico = to_categorical(y)
print("\n--- Labels One-Hot Encoded (y_categorico- primeiros 5)---")
print(y_categorico[:5])
# 4. Dividir os dados em conjuntos de treino e teste
X_treino, X_teste, y_treino, y_teste = train_test_split(
X_normalizado, y_categorico, test_size=0.2, random_state=42, stratify=y)
print(f"Shape de X_treino: {X_treino.shape}")
print(f"Shape de y_treino: {y_treino.shape}")
print(f"Shape de X_teste: {X_teste.shape}")
print(f"Shape de y_teste: {y_teste.shape}")

# 1. Definir a arquitetura
modelo_solo = Sequential()
modelo_solo.add(Dense(32, input_shape=(X_treino.shape[1],), activation='relu'))
modelo_solo.add(Dense(16, activation='relu'))
modelo_solo.add(Dropout(0.5))
modelo_solo.add(Dense(64, activation='relu'))
modelo_solo.add(BatchNormalization())
modelo_solo.add(Dropout(0.5))
modelo_solo.add(Dense(y_treino.shape[1], activation='softmax'))

# Camada de saída
# 2. Compilar o modelo
modelo_solo.compile(optimizer= tf.keras.optimizers.Adam(learning_rate= 0.0005), loss='categorical_crossentropy', metrics=['accuracy'])
# 3. Exibir resumo do modelo
print("\n--- Resumo do Modelo---")
modelo_solo.summary()


# Iniciando Treinamento do  modelo 
print("\n--- Iniciando o Treinamento do Modelo---")

# =-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=

early_stop = EarlyStopping(monitor='val_loss',
                           patience=5,
                           restore_best_weights=True)

# =-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=

reduce_lr = ReduceLROnPlateau(monitor='val_loss', 
                              factor=0.5, 
                              patience=3, 
                              min_lr=1e-6)

# =-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=

num_epocas = 60
tamanho_lote = 16

# =-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=

historico_treinamento = modelo_solo.fit(X_treino,y_treino,
                                        epochs=num_epocas,
                                        batch_size=tamanho_lote,
                                        validation_data= (X_teste,y_teste),
                                        verbose=1,
                                        callbacks=[early_stop, reduce_lr]
                                        )

# =-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=

print("\n--- Treinamento Concluído---")
print("\nChaves disponíveis no histórico de treinamento:")
print(historico_treinamento.history.keys())

# =-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=

# 1. Avaliar no conjunto de teste
print("\n--- Avaliando o Modelo no Conjunto de Teste---")
perda_teste, precisao_teste = modelo_solo.evaluate(X_teste, y_teste, verbose=0)

# =-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=

print(f"Perda no conjunto de teste: {perda_teste:.4f}")
print(f"Precisão no conjunto de teste: {precisao_teste:.4f} (ou precisao_teste*100:.2f%)")

# 2. Visualizar histórico de treinamento (Precisão e Perda)
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(historico_treinamento.history['accuracy'], label=' Precisão (Treino)')
plt.plot(historico_treinamento.history['val_accuracy'], label=' Precisão (Validação)')
plt.title('Histórico de Precisão')
plt.xlabel('Época')
plt.ylabel('Precisão')
plt.legend()
plt.grid(True)

# =-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=

plt.subplot(1, 2, 2)
plt.plot(historico_treinamento.history['loss'], label='Perda (Treino)')
plt.plot(historico_treinamento.history['val_loss'], label='Perda (Validação)')
plt.title('Histórico de Perda')
plt.xlabel('Época')
plt.ylabel('Perda')
plt.legend()
plt.grid(True)

# =-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=

plt.tight_layout()
plt.show()

# 3. Matriz de Confusão e Relatório de Classificação
y_pred_prob = modelo_solo.predict(X_teste)
y_pred_classes = np.argmax(y_pred_prob, axis=1)
y_teste_classes = np.argmax(y_teste, axis=1) # Converter y_teste de one-hot

print("\n--- Relatório de Classificação---")
print(classification_report(y_teste_classes, y_pred_classes,
target_names=['Baixa Fertilidade.', 'Média Fertilidade.', 'Alta Fertilidade.']))
mat_conf = confusion_matrix(y_teste_classes, y_pred_classes)
plt.figure(figsize=(8, 6))
sns.heatmap(mat_conf, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['Baixa Fertilidade.', 'Média Fertilidade.', 'Alta Fertilidade.'], 
            yticklabels=['Baixa Fertilidade.', 'Média Fertilidade.', 'Alta Fertilidade.'])
plt.title('Matriz de Confusão')
plt.ylabel('Classe Verdadeira')
plt.xlabel('Classe Prevista')
plt.show()

salvarModelo(modelo_solo, historico_treinamento)